{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Advanced Transliteration Pipeline Playground\n",
                "\n",
                "Use this notebook to interactively test the 7-step hybrid transliteration pipeline.\n",
                "\n",
                "## Setup\n",
                "Run the cell below to load the necessary modules."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Modules loaded successfully!\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "# Add project root to path\n",
                "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
                "\n",
                "from services.transliteration_core import (\n",
                "    calculate_name_similarity,\n",
                "    tokenize_arabic_name,\n",
                "    tokenize_latin_name,\n",
                "    arabic_to_latin,\n",
                "    jaro_winkler_similarity,\n",
                ")\n",
                "from utils.text_normalization import (\n",
                "    normalize_arabic,\n",
                "    normalize_latin,\n",
                ")\n",
                "\n",
                "print(\"Modules loaded successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Arabic Normalization\n",
                "Test how Arabic text is normalized (diacritics removed, alef unified, etc.)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Original: أحمد\n",
                        "Normalized: احمد\n",
                        "---\n",
                        "Original: محمّد\n",
                        "Normalized: محمد\n",
                        "---\n",
                        "Original: فاطمة\n",
                        "Normalized: فاطمه\n",
                        "---\n",
                        "Original: عبدالله\n",
                        "Normalized: عبدالله\n",
                        "---\n"
                    ]
                }
            ],
            "source": [
                "arabic_names = [\n",
                "    \"أحمد\",\n",
                "    \"محمّد\",\n",
                "    \"فاطمة\",\n",
                "    \"عبدالله\"\n",
                "]\n",
                "\n",
                "for name in arabic_names:\n",
                "    normalized = normalize_arabic(name)\n",
                "    print(f\"Original: {name}\\nNormalized: {normalized}\\n---\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Tokenization\n",
                "See how names are split into tokens (handling compounds like \"Abdullah\" or \"Bin\")."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Arabic: 'عبدالله محمد' -> ['عبد', 'الله', 'محمد']\n",
                        "Arabic: 'أحمد بن سعيد' -> ['احمد', 'بن', 'سعيد']\n",
                        "Latin: 'Abdullah Mohammed' -> ['abd', 'al', 'lah', 'mohammed']\n",
                        "Latin: 'Ahmed bin Saeed' -> ['ahmed', 'bin', 'said']\n"
                    ]
                }
            ],
            "source": [
                "names_to_tokenize = [\n",
                "    \"عبدالله محمد\",\n",
                "    \"أحمد بن سعيد\",\n",
                "    \"Abdullah Mohammed\",\n",
                "    \"Ahmed bin Saeed\"\n",
                "]\n",
                "\n",
                "for name in names_to_tokenize:\n",
                "    # Auto-detect language for tokenization demo\n",
                "    if any(\"\\u0600\" <= c <= \"\\u06FF\" for c in name):\n",
                "        tokens = tokenize_arabic_name(name)\n",
                "        lang = \"Arabic\"\n",
                "    else:\n",
                "        tokens = tokenize_latin_name(name)\n",
                "        lang = \"Latin\"\n",
                "        \n",
                "    print(f\"{lang}: '{name}' -> {tokens}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Cross-Script Bridge (Arabic -> Latin)\n",
                "Test the transliteration logic that converts Arabic names to Latin characters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "'أحمد' -> 'Ahmd'\n",
                        "'محمد' -> 'Mhmd'\n",
                        "'فاطمة' -> 'Fatmh'\n",
                        "'سماح جابر' -> 'Smah Jabr'\n"
                    ]
                }
            ],
            "source": [
                "arabic_names = [\n",
                "    \"أحمد\",\n",
                "    \"محمد\",\n",
                "    \"فاطمة\",\n",
                "    \"سماح جابر\"\n",
                "]\n",
                "\n",
                "for name in arabic_names:\n",
                "    latin = arabic_to_latin(name)\n",
                "    print(f\"'{name}' -> '{latin}'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Full Pipeline Test\n",
                "Enter two names (OCR and User Input) to see the full 7-step comparison results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Comparing:\n",
                        "  1. سوجاتا\n",
                        "  2. Sujita\n",
                        "\n",
                        "PIPELINE RESULTS:\n",
                        "1. Normalized (OCR):  'سوجاتا'\n",
                        "2. Normalized (User): 'sujita'\n",
                        "3. Tokens (OCR):  ['سوجاتا']\n",
                        "4. Tokens (User): ['sujita']\n",
                        "5. Latin Bridge:  'Sojata'\n",
                        "6. Latin Phonetic:  1.000\n",
                        "7. Final Score:     1.000\n"
                    ]
                }
            ],
            "source": [
                "# EDIT THESE NAMES TO TEST\n",
                "ocr_name = \"سوجاتا\"\n",
                "user_name = \"Sujita\"\n",
                "\n",
                "print(f\"Comparing:\\n  1. {ocr_name}\\n  2. {user_name}\\n\")\n",
                "\n",
                "result = calculate_name_similarity(ocr_name, user_name)\n",
                "\n",
                "print(\"PIPELINE RESULTS:\")\n",
                "print(f\"1. Normalized (OCR):  '{result['normalized']['text1_arabic']}'\")\n",
                "print(f\"2. Normalized (User): '{result['normalized']['text2_latin']}'\")\n",
                "print(f\"3. Tokens (OCR):  {result['tokens']['text1']}\")\n",
                "print(f\"4. Tokens (User): {result['tokens']['text2']}\")\n",
                "print(f\"5. Latin Bridge:  '{result['latin_bridges']['text1_to_latin']}'\")\n",
                "print(f\"6. Latin Phonetic:  {result['latin_phonetic_similarity']:.3f}\")\n",
                "print(f\"7. Final Score:     {result['final_score']:.3f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
